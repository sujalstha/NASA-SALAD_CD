# -*- coding: utf-8 -*-
"""SALaD-CD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15H1a-xwaxtTalauYXG1OZMF2l_pQ9_wB
"""

# Copyright Â© 2020 United States Government as represented by the
# Administrator of the National Aeronautics and Space Administration.
# All Rights Reserved.

# For reference see: https://doi.org/10.1002/gdj3.145

# Install required files for SALaD-CD
# Mount Gdrive
from google.colab import drive
drive.mount("/content/gdrive/")

# Download OTB
!wget https://www.orfeo-toolbox.org/packages/archives/OTB/OTB-8.1.2-Linux64.run
!apt-get install file

# Required tools to run OTB apps with graphical interface
!apt install -y --no-install-recommends libgl-dev

# Configure OTB
!chmod +x OTB-8.1.2-Linux64.run && ./OTB-8.1.2-Linux64.run && cd OTB-8.1.2-Linux64 && ctest -S share/otb/swig/build_wrapping.cmake -VV

# Configure OTB environment variables
import os, sys
os.environ["CMAKE_PREFIX_PATH"] = "/content/OTB-8.1.2-Linux64"
os.environ["OTB_APPLICATION_PATH"] = "/content/OTB-8.1.2-Linux64/lib/otb/applications"
os.environ["PATH"] = "/content/OTB-8.1.2-Linux64/bin" + os.pathsep + os.environ["PATH"]
sys.path.insert(0, "/content/OTB-8.1.2-Linux64/lib/python")
os.environ["OTB_MAX_RAM_HINT"] = "10000"

# Download input file from Gdrive and unzip in Colab
! gdown --id 1tsKW-ifAa5xrdufCu4nl1Kl3zS4nUcYd
! mkdir /content/salad_cd
! unzip input_cd.zip -d /content/salad_cd

# Create a output directory in Gdrive
! mkdir -p /content/gdrive/MyDrive/output/salad_cd

#Install required Python packages
! pip install pyogrio

!which python

# Display post-event Sentinel-2 imagery interactively using Folium

from osgeo import gdal
import numpy as np
import folium

image="/content/salad_cd/20210216_post_clip.tif"

# Resample image to WGS for use in Folium
output_raster="/content/salad_cd/20210216_post_clip_wgs.tif"
gdal.Warp(output_raster,image,dstSRS='EPSG:4326')

# Normalize imagery for display
img=gdal.Open(output_raster)
img_array = img.ReadAsArray()
rgb = img_array[[2,1,0]].transpose(1,2,0)

def brighten(band):
    alpha=0.13
    beta=0
    return np.clip(alpha*band+beta, 0,255)

def normalize(band):
    band_min, band_max = (band.min(), band.max())
    return ((band-band_min)/((band_max - band_min)))

red_br=brighten(rgb[:,:,0])
green_br=brighten(rgb[:,:,1])
blue_br=brighten(rgb[:,:,2])

red_norm=normalize(red_br)
green_norm=normalize(green_br)
blue_norm=normalize(blue_br)

rgb_norm= np.dstack((red_norm, green_norm, blue_norm))
#plt.imshow(rgb_norm)

# Get corner coordiantes
geo=img.GetGeoTransform()
proj=img.GetProjection()

rows = img.RasterYSize
cols = img.RasterXSize

ulx = geo[0]
uly = geo[3]
lrx = ulx + geo[1] * cols
lry = uly + geo[5] * rows

#Load in Folium
map = folium.Map(location=[15.29, 107.89], zoom_start=12)
map_bounds = [[uly , ulx],[lry, lrx]]
map.add_child(folium.raster_layers.ImageOverlay(rgb_norm, opacity=1,bounds=map_bounds, name="Sentinel-2"))
map.add_child(folium.LayerControl())
map



#SALaD-CD
import os
import glob
from osgeo import gdal, ogr, osr
import numpy as np
from sklearn.decomposition import PCA
from sklearn.decomposition import FastICA
import otbApplication
import geopandas as gpd
from geopandas.tools import sjoin
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from pyogrio import read_dataframe
import time


def preprocessing(in_path,pre_image,post_image,out_path,comp_name):
    # Prepare inputs for SALaD-CD

    # Open the imagery
    img_pre = gdal.Open(in_path+pre_image)
    img_post= gdal.Open(in_path+post_image)

    # Get the number of rows and columns of the imagery
    rows = img_pre.RasterYSize
    cols = img_pre.RasterXSize

    # Convert pre image bands to float and calculate mean and standard deviation of each band
    blue_pre = img_pre.GetRasterBand(1).ReadAsArray().astype(np.float32)
    green_pre = img_pre.GetRasterBand(2).ReadAsArray().astype(np.float32)
    red_pre = img_pre.GetRasterBand(3).ReadAsArray().astype(np.float32)
    nir_pre = img_pre.GetRasterBand(4).ReadAsArray().astype(np.float32)

    blue_pre_mean=np.mean(blue_pre)
    green_pre_mean=np.mean(green_pre)
    red_pre_mean=np.mean(red_pre)
    nir_pre_mean=np.mean(nir_pre)

    blue_pre_std=np.std(blue_pre)
    green_pre_std=np.std(green_pre)
    red_pre_std=np.std(red_pre)
    nir_pre_std=np.std(nir_pre)

    # Convert post image bands to float and calculate mean and standard deviation of each band
    blue_post = img_post.GetRasterBand(1).ReadAsArray().astype(np.float32)
    green_post = img_post.GetRasterBand(2).ReadAsArray().astype(np.float32)
    red_post = img_post.GetRasterBand(3).ReadAsArray().astype(np.float32)
    nir_post = img_post.GetRasterBand(4).ReadAsArray().astype(np.float32)

    blue_post_mean=np.mean(blue_post)
    green_post_mean=np.mean(green_post)
    red_post_mean=np.mean(red_post)
    nir_post_mean=np.mean(nir_post)

    blue_post_std=np.std(blue_post)
    green_post_std=np.std(green_post)
    red_post_std=np.std(red_post)
    nir_post_std=np.std(nir_post)

    #Normalize post event bands to pre image bands using relative normalization
    blue_post_norm=(blue_post-blue_post_mean)*(blue_pre_std/blue_post_std)+blue_pre_mean
    green_post_norm=(green_post-green_post_mean)*(green_pre_std/green_post_std)+green_pre_mean
    red_post_norm=(red_post-red_post_mean)*(red_pre_std/red_post_std)+red_pre_mean
    nir_post_norm=(nir_post-nir_post_mean)*(nir_pre_std/nir_post_std)+nir_pre_mean

    #Calculate NDVI difference
    np.seterr(divide='ignore', invalid='ignore')

    ndvi_pre=(nir_pre-red_pre)/(nir_pre+red_pre)
    ndvi_post=(nir_post_norm-red_post_norm)/(nir_post_norm+red_post_norm)

    ndvi_diff=ndvi_pre-ndvi_post

    # Calcualte PCA and ICA
    blue_pre_flat=blue_pre.flatten()
    green_pre_flat=green_pre.flatten()
    red_pre_flat=red_pre.flatten()
    nir_pre_flat=nir_pre.flatten()

    blue_post_flat=blue_post_norm.flatten()
    green_post_flat=green_post_norm.flatten()
    red_post_flat=red_post_norm.flatten()
    nir_post_flat=nir_post_norm.flatten()

    data=[]
    data.append(blue_pre_flat)
    data.append(green_pre_flat)
    data.append(red_pre_flat)
    data.append(nir_pre_flat)
    data.append(blue_post_flat)
    data.append(green_post_flat)
    data.append(red_post_flat)
    data.append(nir_post_flat)

    pca = PCA(n_components=4)
    pca.fit(data)

    ica = FastICA(n_components = 4)
    ica.fit(data)

    pc1=pca.components_[0].reshape(rows,cols)
    pc2=pca.components_[1].reshape(rows,cols)
    pc3=pca.components_[2].reshape(rows,cols)
    pc4=pca.components_[3].reshape(rows,cols)

    ica1=ica.components_[0].reshape(rows,cols)
    ica2=ica.components_[1].reshape(rows,cols)
    ica3=ica.components_[2].reshape(rows,cols)
    ica4=ica.components_[3].reshape(rows,cols)

    ica1=ica1*1000000000
    ica2=ica2*1000000000
    ica3=ica3*1000000000
    ica4=ica4*1000000000

    # Get geometry and projection for saving output
    driver=gdal.GetDriverByName("GTiff")
    geo=img_pre.GetGeoTransform()
    proj=img_pre.GetProjection()

    # Save composite image to output folder
    output=driver.Create(out_path+comp_name,cols,rows,9,gdal.GDT_Float32)
    output.SetGeoTransform(geo)
    output.SetProjection(proj)
    output.GetRasterBand(1).WriteArray(ndvi_diff)
    output.GetRasterBand(2).WriteArray(pc1)
    output.GetRasterBand(3).WriteArray(pc2)
    output.GetRasterBand(4).WriteArray(pc3)
    output.GetRasterBand(5).WriteArray(pc4)
    output.GetRasterBand(6).WriteArray(ica1)
    output.GetRasterBand(7).WriteArray(ica2)
    output.GetRasterBand(8).WriteArray(ica3)
    output.GetRasterBand(9).WriteArray(ica4)

    output = None

def mean_shift(in_path,post_image,spatial_r,range_r,min_size,out_path,seg_shpname):
    # Generates objects using Mean-Shift segmentation in OTB

    name = post_image.split('/')[-1].split('.')[0]

    #Set output filenames
    outfile1=out_path+"sm_"+name+".tif"
    outfile2=out_path+"seg_"+name+".tif"
    outfile3=out_path+"merg_"+name+".tif"
    outfile4=out_path+seg_shpname

    # The following line creates an instance of the MeanShiftSmoothing application
    MeanShiftSmoothing = otbApplication.Registry.CreateApplication("MeanShiftSmoothing")

    # The following lines set all the application parameters:
    MeanShiftSmoothing.SetParameterString("in", in_path+post_image)

    MeanShiftSmoothing.SetParameterString("fout", outfile1)

    MeanShiftSmoothing.SetParameterInt("spatialr", spatial_r)

    MeanShiftSmoothing.SetParameterFloat("ranger", range_r)

    MeanShiftSmoothing.SetParameterFloat("thres", 0.1)

    MeanShiftSmoothing.SetParameterInt("maxiter", 100)

    # The following line execute the application
    MeanShiftSmoothing.ExecuteAndWriteOutput()

    # The following line creates an instance of the LSMSSegmentation application
    LSMSSegmentation = otbApplication.Registry.CreateApplication("LSMSSegmentation")

    # The following lines set all the application parameters:
    LSMSSegmentation.SetParameterString("in", outfile1)

    LSMSSegmentation.SetParameterString("out", outfile2)

    LSMSSegmentation.SetParameterFloat("spatialr", spatial_r)

    LSMSSegmentation.SetParameterFloat("ranger", range_r)

    LSMSSegmentation.SetParameterInt("minsize", 0)

    LSMSSegmentation.SetParameterInt("tilesizex", 500)

    LSMSSegmentation.SetParameterInt("tilesizey", 500)

    # The following line execute the application
    LSMSSegmentation.ExecuteAndWriteOutput()

    # The following line creates an instance of the LSMSSmallRegionsMerging application
    LSMSSmallRegionsMerging = otbApplication.Registry.CreateApplication("LSMSSmallRegionsMerging")

    # The following lines set all the application parameters:
    LSMSSmallRegionsMerging.SetParameterString("in", in_path+post_image)

    LSMSSmallRegionsMerging.SetParameterString("inseg", outfile2)

    LSMSSmallRegionsMerging.SetParameterString("out", outfile3)

    LSMSSmallRegionsMerging.SetParameterInt("minsize", min_size)

    LSMSSmallRegionsMerging.SetParameterInt("tilesizex", 500)

    LSMSSmallRegionsMerging.SetParameterInt("tilesizey", 500)

    # The following line execute the application
    LSMSSmallRegionsMerging.ExecuteAndWriteOutput()

    #Convert LSMSSmallRegionsMerging output raster to polygon
    #Get spatial reference from LSMSSmallRegionsMerging raster
    src_ds = gdal.Open( outfile3 )
    srcband = src_ds.GetRasterBand(1)
    srs = osr.SpatialReference()
    srs.ImportFromWkt(src_ds.GetProjection())

    # Create output shapefile
    drv = ogr.GetDriverByName("ESRI Shapefile")
    dst_ds = drv.CreateDataSource(outfile4)
    dst_layer = dst_ds.CreateLayer(outfile4, srs = srs )
    gdal.Polygonize( srcband, None, dst_layer, -1, [], callback=None )
    dst_ds = None

    # Delete temporary files created during segmentation
    #for f in glob.glob("seg_*_FINAL.tif"):
        #os.remove(f)

def zonal_stats(out_path,comp_name,seg_shpname,zonal_shpname):
    # Compute object mean using zonal statistics
    app = otbApplication.Registry.CreateApplication("ZonalStatistics")
    app.SetParameterString("in", out_path+comp_name)
    app.SetParameterString("inzone.vector.in", out_path+seg_shpname)
    app.SetParameterString("out.vector.filename", out_path+zonal_shpname)
    app.ExecuteAndWriteOutput()

    for f in glob.glob(out_path+"MSsegment.*"):
        os.remove(f)

def train_file(in_path,landslide,nonlandslide,out_path,zonal_shpname,train_shpname):
    # Generate a training file
    files_to_process = glob.glob(in_path+"*.shp")

    for files in files_to_process[:2]:
        file=os.path.basename(files)
        name = file.split(".")[0]

        #select_feature = gpd.read_file(files)
        #input_feature = gpd.read_file(out_path+zonal_shpname,encoding="utf-8")
        select_feature = read_dataframe(files)
        input_feature = read_dataframe(out_path+zonal_shpname,encoding="utf-8")
        selection= gpd.sjoin(input_feature, select_feature, how="inner", op="intersects")
        selection["segment_ar"] = selection["geometry"].area
        final_select=selection[selection["index_right"]>0]

        intersections=gpd.overlay(select_feature, final_select, how="intersection")
        intersections["overlap_ar"] = intersections["geometry"].area
        intersections["percentage"] = intersections["overlap_ar"]/intersections["segment_ar"]*100
        intersections = intersections.loc[:, ["geometry","percentage"]]
        final_intersect=intersections[intersections["percentage"]>50]

        final= gpd.sjoin(input_feature, final_intersect, how="inner", op='contains')
        if name == "landslide":
            final["landslide"]=1
        else:
            final["landslide"]=0
        final.drop(["percentage"], axis=1, inplace=True)
        final.drop(["index_right"], axis=1, inplace=True)
        final.to_file(out_path+name+"_train.shp")

    crs=input_feature.crs
    #land = gpd.read_file(out_path+"landslide_train.shp")
    #nonland = gpd.read_file(out_path+"nonlandslide_train.shp")
    land = read_dataframe(out_path+"landslide_train.shp")
    nonland = read_dataframe(out_path+"nonlandslide_train.shp")
    merge = gpd.GeoDataFrame(pd.concat([land, nonland],ignore_index=True))
    merge.crs = crs
    merge.to_file(out_path+train_shpname)
    for f in glob.glob(out_path+"landslide_*.*"):
        os.remove(f)
    for g in glob.glob(out_path+"nonlandslide_*.*"):
        os.remove(g)

def predict(out_path,train_shpname,zonal_shpname,final_name):
    # Predict landslides using Random forest
    #df_train = gpd.read_file(out_path+train_shpname,encoding="utf-8")
    #df_test=gpd.read_file(out_path+zonal_shpname,encoding="utf-8")
    df_train = read_dataframe(out_path+train_shpname,encoding="utf-8")
    df_test=read_dataframe(out_path+zonal_shpname,encoding="utf-8")
    df_test.fillna(0, inplace=True)

    predictor_vars = ["mean_0","mean_1","mean_2","mean_3","mean_4","mean_5","mean_6","mean_7","mean_8"]
    x,y = df_train[predictor_vars],df_train.landslide

    modelRandom = RandomForestClassifier(n_estimators=5000)
    modelRandom.fit(x,y)

    predictions=modelRandom.predict(df_test[predictor_vars])
    #prob=modelRandom.predict_proba(df_test[predictor_vars])[:,1]
    df_test["outcomes"]= predictions
    #df_test["probability"]= prob

    crs=df_test.crs

    df_land=df_test[df_test["outcomes"]>0]
    #df_land=df_land[df_land['probability']>=0.9]
    df_land_dissolve = gpd.geoseries.GeoSeries([geom for geom in df_land.unary_union.geoms])
    df_land_dissolve.crs=crs
    df_land_dissolve.to_file(out_path+final_name)

    # Save final result in GeoJson to visualize in Folium
    df_land_json=df_land_dissolve.to_crs({'init': 'epsg:4326'})
    df_land_json.to_file(out_path+final_name.split(".")[0]+".json", driver="GeoJSON")

#######################################################################################################################
# only change below this section
t0=time.time()

# Set input and output
#
in_path="/content/salad_cd/"
pre_image="20200123_pre_clip.tif"
post_image="20210216_post_clip.tif"
out_path="/content/gdrive/MyDrive/output/salad_cd/"
composite_filename="composite.tif"

preprocessing(in_path,pre_image,post_image,out_path,composite_filename)

seg_shpname="MSsegment.shp"
spatial_r=10
range_r=70
min_size=10
mean_shift(in_path,post_image,spatial_r,range_r,min_size,out_path,seg_shpname)

zonal_shpname="zonal_segment.shp"
zonal_stats(out_path,composite_filename,seg_shpname,zonal_shpname)

landslide="landslides.shp"
nonlandslide="nonlandslide.shp"
train_shpname="training.shp"
train_file(in_path,landslide,nonlandslide,out_path,zonal_shpname,train_shpname)

final_name="Landslide_SALaD_CD.shp"
predict(out_path,train_shpname,zonal_shpname,final_name)

#Print total time for processing
final=((time.time()-t0)/60)
print("Finished in",final, "mins")

# Zip landslide shapefile, post-event tiff and download
!zip -j /content/landslide_cd.zip /content/gdrive/MyDrive/output/salad_cd/Landslide_SALaD_CD.* /content/salad_cd/20210216_post_clip.*
from google.colab import files
files.download("landslide_cd.zip")

files.download("landslide_cd.zip")

# Visualize final result in Folium
import json

file = out_path+final_name.split(".")[0]+".json"
geo_json_data = json.load(open(file))
map = folium.Map(location=[15.29, 107.89], zoom_start=12, tiles="Stamen Terrain")
#map.add_child(folium.raster_layers.ImageOverlay(rgb_norm, opacity=1,bounds=map_bounds,name="Sentinel-2"))
map.add_child(folium.raster_layers.ImageOverlay(red_norm, opacity=1,bounds=map_bounds,name="Sentinel-2"))
map.add_child(folium.GeoJson(geo_json_data, style_function=lambda feature: {"fillColor": "none","color": "red","weight": 1},name="SALaD-CD landslides"))
map.add_child(folium.LayerControl())
map